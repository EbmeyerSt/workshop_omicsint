{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6906e3-e682-4e4b-a5bc-9efbff8f4fe8",
   "metadata": {},
   "source": [
    "# Graph Neural Networks in Integrative Omics\n",
    "- Sergiu Netotea, NBIS, 2024\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34032f66-887a-4cb4-b0ab-1f5d05dd0280",
   "metadata": {},
   "source": [
    "TODO: graph embeddings, geometric learning, graph models in LLMs, graph transformers\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/tutorial/shallow_node_embeddings.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cb2d98-d2b3-4284-90dd-0c5060a59a44",
   "metadata": {},
   "source": [
    "## Graph Convolutional Networks (GCNs)\n",
    "\n",
    "- **Description**: GCNs generalize convolutional operations to graph-structured data, focusing on neighborhood aggregation.\n",
    "- **Example Uses**: Social network analysis, where the goal is to predict user behavior based on the connections and interactions between users. Predicting labels of nodes in a partially labeled graph (e.g., classifying users in a social network). Predicting whether an edge exists between two nodes (e.g., friend recommendation in social networks). Classifying entire graphs (e.g., classifying molecules based on their structure).\n",
    "- **Single-cell Transcriptomics:** GCNs can model gene-gene interactions across different cells by representing the cells as nodes and the gene expression correlations as edges. This helps identify cell types and gene regulatory networks.\n",
    "    - > Wang, T., Bai, J. & Nabavi, S. Single-cell classification using graph convolutional networks. BMC Bioinformatics 22, 364 (2021). https://doi.org/10.1186/s12859-021-04278-2\n",
    "    - > Yuan, Y., Bar-Joseph, Z. GCNG: graph convolutional networks for inferring gene interaction from spatial transcriptomics data. Genome Biol 21, 300 (2020). https://doi.org/10.1186/s13059-020-02214-w\n",
    "- **Bulk RNA-Seq & omics integration:** GCNs can be used to integrate bulk transcriptomic data with other omics data (like DNA methylation, protein, etc) by constructing a graph where nodes represent genes, and edges represent regulatory relationships, helping in uncovering gene expression regulation patterns.\n",
    "    - > Wang, T., Shao, W., Huang, Z. et al. MOGONET integrates multi-omics data using graph convolutional networks allowing patient classification and biomarker identification. Nat Commun 12, 3445 (2021). https://doi.org/10.1038/s41467-021-23774-w\n",
    "    - > Chuang, YH., Huang, SH., Hung, TM. et al. Convolutional neural network for human cancer types prediction by integrating protein interaction networks and omics data. Sci Rep 11, 20691 (2021). https://doi.org/10.1038/s41598-021-98814-y\n",
    "    -  > Ji, R., Geng, Y. & Quan, X. Inferring gene regulatory networks with graph convolutional network based on causal feature reconstruction. Sci Rep 14, 21342 (2024). https://doi.org/10.1038/s41598-024-71864-8\n",
    "\n",
    "__Key Concepts in GCNs__\n",
    "\n",
    "- **Graph Structure**: A graph G is typically represented by a set of nodes V, a set of edges E, where each edge connects two nodes. From the graph structure one can derive an adjacency matrix A. Apart \n",
    "- **Node Features**: Each node can have a feature vector associated with it. For example, in a single cell dataset the feature can be gene expression associated to a node.\n",
    "- **Message Passing and Aggregation**: The core mechanism in GCNs is the aggregation of information from a node's neighbors to update the node's feature representation. This process, sometimes called \"message passing,\" allows a node to gain a more informed representation based on its graph context.\n",
    "\n",
    "\n",
    "__GCN Layer (Graph Convolution Layer)__\n",
    "\n",
    "A GCN layer generalizes the concept of the standard convolutional layer. Instead of applying a kernel to a grid of pixels (as in CNNs), GCN layers perform a neighborhood aggregation operation. \n",
    "\n",
    "For each layer in a GCN, the node feature matrix $ H $ is updated as follows:\n",
    "$$\n",
    "H^{(l+1)} = \\sigma\\left( \\hat{A} H^{(l)} W^{(l)} \\right)\n",
    "$$\n",
    "Where:\n",
    "- $ H^{(l)} $ is the feature matrix at layer $ l $, with shape $ N \\times D_l $ (i.e., $ N $ nodes and $ D_l $ features per node at layer $ l $).\n",
    "- $ \\hat{A} $ is the adjacency matrix of the graph, normalized to prevent the exploding or vanishing of feature values.\n",
    "- $ W^{(l)} $ is the learnable weight matrix at layer $ l $.\n",
    "- $ \\sigma $ is an activation function, such as ReLU.\n",
    "\n",
    "Main idea:\n",
    "- Neighborhood Aggregation: Instead of using a fixed kernel, the graph structure dictates how information is shared between nodes.\n",
    "- Weight Transformation: The aggregated features are transformed using a weight matrix, which is learned during training. This step is similar to the linear transformation in fully connected layers of neural networks.\n",
    "- The activation function, such as ReLU, is applied to introduce non-linearity, allowing the model to capture complex patterns in the graph.\n",
    "- Multi-Layer GCN: A GCN typically stacks multiple graph convolutional layers. Each layer aggregates more information from a larger neighborhood in the graph. After multiple layers, a node’s representation is influenced not only by its immediate neighbors but also by neighbors that are further away.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1facef6c-ef76-4be4-a818-481131aae356",
   "metadata": {},
   "source": [
    "## Graph Attention Networks (GAT)\n",
    "\n",
    "- **Description**: GATs use attention mechanisms to learn the importance of neighboring nodes when aggregating information. This allows the model to focus on the most relevant neighbors when updating a node's features.\n",
    "- **Example Use**: Citation networks, where a paper's relevance is predicted by selectively focusing on certain referenced papers.\n",
    "- **Spatial Transcriptomics, SCRNA-Seq:** GATs can model spatial relationships between neighboring cells by treating each cell as a node, with attention mechanisms helping focus on spatially relevant neighboring cells. This allows for more accurate spatial gene expression patterns to emerge.\n",
    "    - > Sun H, Qu H, Duan K, Du W. scMGCN: A Multi-View Graph Convolutional Network for Cell Type Identification in scRNA-seq Data. Int J Mol Sci. 2024 Feb 13;25(4):2234. doi: 10.3390/ijms25042234. PMID: 38396909; PMCID: PMC10889820.\n",
    "    - > Yang, W., Wang, P., Xu, S. et al. Deciphering cell–cell communication at single-cell resolution for spatial transcriptomics with subgraph-based graph attention network. Nat Commun 15, 7101 (2024). https://doi.org/10.1038/s41467-024-51329-2\n",
    "    - > Zizhan Gao, Kai Cao, Lin Wan, Graspot: a graph attention network for spatial transcriptomics data integration with optimal transport, Bioinformatics, Volume 40, Issue Supplement_2, September 2024, Pages ii137–ii145, https://doi.org/10.1093/bioinformatics/btae394\n",
    "    - > Long, Y., Ang, K.S., Li, M. et al. Spatially informed clustering, integration, and deconvolution of spatial transcriptomics with GraphST. Nat Commun 14, 1155 (2023). https://doi.org/10.1038/s41467-023-36796-3\n",
    "    -  > Guangyi Chen, Zhi-Ping Liu, Graph attention network for link prediction of gene regulations from single-cell RNA-sequencing data, Bioinformatics, Volume 38, Issue 19, October 2022, Pages 4522–4529, https://doi.org/10.1093/bioinformatics/btac559\n",
    "    -  > Li, H., Han, Z., Sun, Y. et al. CGMega: explainable graph neural network framework with attention mechanisms for cancer gene module dissection. Nat Commun 15, 5997 (2024). https://doi.org/10.1038/s41467-024-50426-6\n",
    "- **Metagenomics:** In metagenomic studies, GATs can integrate various layers of data, such as species abundance and functional annotations, by focusing on the most relevant species in a microbiome community, helping identify key microbes involved in disease.\n",
    "    - > Andre Lamurias, Mantas Sereika, Mads Albertsen, Katja Hose, Thomas Dyhre Nielsen, Metagenomic binning with assembly graph embeddings, Bioinformatics, Volume 38, Issue 19, October 2022, Pages 4481–4487, https://doi.org/10.1093/bioinformatics/btac557\n",
    "\n",
    "__Key concepts in GANs__ \n",
    "- Problem with Basic GNNs: In traditional GNNs, the information from neighboring nodes is aggregated uniformly, assuming all neighbors have equal importance. This may result in a loss of relevant information. Graph Attention Networks (GAT) are a type of neural network designed to process graph-structured data by leveraging the **attention mechanism** to assign different weights to neighboring nodes. \n",
    "- Input Features: Each node $ v_i \\in V $ is associated with a feature vector $ h_i \\in R^F $ , where $ F $ is the dimensionality of the node features.\n",
    "- Linear Transformation: First, apply a shared linear transformation to each node's feature vector: $ h_i' = W h_i $, where W is a learnable weight matrix, and f is the transformed feature vector for node i.\n",
    "- **Attention Mechanism**:  For each node $ v_i $, compute attention coefficients for each of its neighboring nodes. The attention coefficient between nodes  i and j  is computed as a non-linear activation function (LeakyReLU) applied on a learnable attention vector and a concatenation based on the concatenation the two nodes transformed feature vectors ( the f - transformed feature vectors for node i and j respectively). **Self-Attention**: Attends to node pairs independently of the graph structure, making the model more flexible.\n",
    "  $$\n",
    "  e_{ij} = \\text{LeakyReLU}\\left( a^T [ h_i' \\, || \\, h_j' ] \\right)\n",
    "  $$\n",
    "- Normalization of attention coefficients (Softmax) to make them comparable  \n",
    "   $$\n",
    "   \\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k \\in N(i)} \\exp(e_{ik})}\n",
    "   $$\n",
    "   where $ \\alpha_{ij} $ represents the normalized attention coefficient, reflecting the importance of node j in the neighborhood of node i .\n",
    "\n",
    "- Aggregation:  \n",
    "   The node features are then updated by aggregating the transformed features of its neighbors, weighted by the attention coefficients:\n",
    "   $$\n",
    "   h_i^{(l+1)} = \\sigma \\left( \\sum_{j \\in N(i)} \\alpha_{ij} h_j' \\right)\n",
    "   $$\n",
    "   , where \\( \\sigma \\) is a non-linear activation function such as ReLU.\n",
    "\n",
    "6. **Multi-head Attention** (optional): To stabilize the learning process and increase model capacity, GAT uses multi-head attention. This means the attention mechanism is applied multiple times in parallel, and the results are concatenated or averaged. For K attention heads, the output for node i after multi-head attention is:\n",
    "   $$\n",
    "   h_i^{(l+1)} = \\, ||_{k=1}^K \\sigma \\left( \\sum_{j \\in N(i)} \\alpha_{ij}^{(k)} h_j'^{(k)} \\right)\n",
    "   $$\n",
    "   where $ ||_{k=1}^K $ denotes concatenation of the results from each attention head $ k $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706396a9-a3a7-467c-bb19-31d1a64f3aa3",
   "metadata": {},
   "source": [
    "## Other Graph NN types\n",
    "\n",
    "Here’s a very incomplete classification of the other graph neural networks (GNNs) along with some example use for each type. Each type of GNN serves a specific purpose, based on the structure and nature of the graph data.\n",
    "\n",
    "**Graph Recurrent Networks (GRN)**\n",
    "- **Description**: GRNs introduce recurrent neural networks to handle graph sequences, useful for dynamic graphs.\n",
    "- **Example Use**: Traffic forecasting, where the road network's state evolves over time, and predictions are made based on previous patterns.\n",
    "- **Single-cell Temporal Analysis:** GRNs can capture time-evolving cellular states in dynamic single-cell experiments. For example, in developmental biology, GRNs can track the progression of cells over time by integrating temporal transcriptomics data.\n",
    "- **Spatial Transcriptomics Time-Series:** For spatial data over time (e.g., tissue healing or disease progression), GRNs can model how spatial expression patterns change, helping understand how spatial gene expression correlates with temporal dynamics.\n",
    "\n",
    "**Graph Autoencoders (GAE)**\n",
    "- **Description**: GAEs learn embeddings by encoding graph structures and then reconstructing the graph from these embeddings.\n",
    "- **Example Use**: Recommendation systems, where user-item interactions are represented as a graph and new recommendations are generated.\n",
    "- **Bulk and Single-cell Omics Integration:** GAEs can be applied to integrate bulk and single-cell data by encoding both types of data into a unified low-dimensional space, capturing common biological signals while reconstructing multi-omics profiles. This can help in identifying shared molecular pathways across different scales.\n",
    "    - > Dong, K., Zhang, S. Deciphering spatial domains from spatially resolved transcriptomics with an adaptive graph attention auto-encoder. Nat Commun 13, 1739 (2022). https://doi.org/10.1038/s41467-022-29439-6\n",
    "    - > STGNNks: Identifying cell types in spatial transcriptomics data based on graph neural network, denoising auto-encoder, and k-sums clustering - ScienceDirect: https://www.sciencedirect.com/science/article/abs/pii/S0010482523009058\n",
    "- **Metagenomics:** In metagenomics, GAEs can encode microbial community structures and gene abundance patterns to infer functional or ecological relationships between microbes, aiding in the identification of microbial communities driving disease.\n",
    "\n",
    "**Spatial-Temporal GNNs**\n",
    "- **Description**: These models integrate spatial and temporal information, capturing both graph structure and time-evolving patterns.\n",
    "- **Example Use**: Predicting pedestrian movement in smart cities by analyzing how the flow of people changes over time.\n",
    "- **Spatial Transcriptomics:** These GNNs can combine spatial gene expression and temporal data to model processes like tissue regeneration, tracking how gene expression in different regions changes over time. It can provide insights into cellular differentiation and tissue architecture.\n",
    "- **Single-cell Multi-omics:** Spatial-temporal GNNs can integrate transcriptomics, epigenomics, and proteomics data from single cells, allowing for a detailed view of cellular dynamics, such as differentiation over time and space, important for developmental biology and cancer studies.\n",
    "\n",
    "**GraphSAGE**\n",
    "- **Description**: GraphSAGE samples a fixed-size neighborhood for each node and aggregates its information, allowing it to scale to larger graphs.\n",
    "- **Example Use**: Large-scale molecular property prediction, where molecular structures are represented as graphs and properties are inferred from sampled subgraphs.\n",
    "- **Single-cell RNA-seq and Proteomics Integration:** GraphSAGE can be used to integrate gene expression data with protein expression data by aggregating information from neighboring cells or samples. This can reveal the co-regulation of genes and proteins, helping to identify pathways active in specific cell types.\n",
    "- **Metagenomics and Bulk Omics:** In metagenomics studies, GraphSAGE can scale to large datasets, integrating microbial abundance and functional genomics (like gene expression) across environments. This can help uncover how microbial communities influence host transcriptomes in different contexts, such as gut health or disease states.\n",
    "    - > Andre Lamurias, Mantas Sereika, Mads Albertsen, Katja Hose, Thomas Dyhre Nielsen, Metagenomic binning with assembly graph embeddings, Bioinformatics, Volume 38, Issue 19, October 2022, Pages 4481–4487, https://doi.org/10.1093/bioinformatics/btac557\n",
    "\n",
    "\n",
    "Libraries, platforms, etc:\n",
    "- Wandy, J., Daly, R. GraphOmics: an interactive platform to explore and integrate multi-omics data. BMC Bioinformatics 22, 603 (2021). https://doi.org/10.1186/s12859-021-04500-1\n",
    "- Comparative Analysis of Multi-Omics Integration Using Advanced Graph Neural Networks for Cancer Classification, Fadi Alharbi, Aleksandar Vakanski, Boyu Zhang, Murtada K. Elbashir, Mohanad Mohammed, https://doi.org/10.48550/arXiv.2410.05325\n",
    "- Stanford Graph ML course: https://snap.stanford.edu/class/cs224w-2023/\n",
    "- https://huggingface.co/blog/intro-graphml\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9721fa2e-0692-4b77-b383-c16caf1080f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
